{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04b403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path \n",
    "from collections import Counter\n",
    "import string\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be659848",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define constants\n",
    "image_height, image_width = 50, 200\n",
    "batch_size = 16\n",
    "\n",
    "data_dir = Path(\"./captcha_images_v2/\")\n",
    "\n",
    "image_paths = sorted(list(map(str, list(data_dir.glob(\"*.png\")))))\n",
    "\n",
    "labels = [img.split(os.path.sep)[-1].split(\".png\")[0] for img in image_paths]\n",
    "\n",
    "print(\"Number of images found: \", len(image_paths))\n",
    "print(\"Number of labels found: \", len(labels))\n",
    "characters = string.ascii_lowercase  + \"0123456789\"\n",
    "\n",
    "print(\"symbols that could be detected : \", characters)\n",
    "print(\"number of symbols : \",len(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647fcdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(label) for label in labels])\n",
    "\n",
    "# Create a set of all unique characters in the labels\n",
    "all_possible_characters = sorted(set(\"\".join(labels)))\n",
    "\n",
    "# Create a mapping of characters to integers and integers to characters\n",
    "char_to_int = {char: i for i, char in enumerate(all_possible_characters)}\n",
    "int_to_char = {i: char for char, i in char_to_int.items()}\n",
    "\n",
    "# Define a function to preprocess an image\n",
    "def preprocess_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=1)  # Grayscale image\n",
    "    image = tf.image.resize(image, (image_height, image_width))\n",
    "    return image\n",
    "\n",
    "# Preprocess images and labels\n",
    "images = [preprocess_image(image_path) for image_path in image_paths]\n",
    "encoded_labels = [[char_to_int[char] for char in label] for label in labels]\n",
    "\n",
    "# Create TensorFlow Datasets\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images, encoded_labels))\n",
    "\n",
    "# shuffle the dataset\n",
    "dataset = dataset.shuffle(buffer_size=len(images))\n",
    "\n",
    "# Split the dataset into training and validation sets (adjust as needed)\n",
    "train_size = int(0.8 * len(image_paths))\n",
    "train_dataset = dataset.take(train_size).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "validation_dataset = dataset.skip(train_size).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b457de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_random_samples(dataset, int_to_char, num_samples=5):\n",
    "\n",
    "\n",
    "    # Create an iterator for the dataset\n",
    "    dataset_iter = iter(dataset)\n",
    "\n",
    "    # Iterate through the random samples and visualize them\n",
    "    for i in range(num_samples):\n",
    "        image, label = next(dataset_iter)\n",
    "\n",
    "        # Decode the label (convert integers to characters)\n",
    "        label = [int_to_char[int(x)] for x in label[0].numpy()]\n",
    "\n",
    "        # Display the image and label\n",
    "        plt.figure(figsize=(4, 2))\n",
    "        plt.imshow(image[0, :, :, 0])\n",
    "        plt.title(\"Label: \" + ''.join(label))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "visualize_random_samples(validation_dataset, int_to_char, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8be27d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_data = layers.Input(shape=(image_height, image_width, 1), name='input_image')\n",
    "    # Standardize values to be in the [0, 1] range\n",
    "    x = layers.Rescaling(1./255)(input_data)\n",
    "\n",
    "    # Transpose the tensor to shape (None, image_width, image_height, 1)\n",
    "    x = layers.Lambda(lambda x: tf.transpose(x, perm=[0, 2, 1, 3]), name=\"transpose\")(x)\n",
    "\n",
    "    # Convolutional layers\n",
    "    x = layers.Conv2D(64, (3, 3), activation=\"relu\", kernel_initializer=tf.keras.initializers.he_normal(), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
    "\n",
    "    x = layers.Conv2D(128, (3, 3), activation=\"relu\", kernel_initializer=tf.keras.initializers.he_normal(), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n",
    "\n",
    "    x = layers.Conv2D(256, (3, 3), activation=\"relu\", kernel_initializer=tf.keras.initializers.he_normal(), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 1), name=\"pool3\")(x) # Pooling over time dimension\n",
    "\n",
    "    x = layers.Reshape(target_shape=(image_width // 8, (image_height // 4) * 256), name=\"reshape\")(x)\n",
    "    x = layers.Dense(128, activation=\"relu\", kernel_initializer=tf.keras.initializers.he_normal())(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "\n",
    "    # Recurrent layers (Bidirectional LSTM)\n",
    "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n",
    "\n",
    "    # Output layer (CTC)\n",
    "    output = layers.Dense(len(characters) + 1, activation='softmax')(x)\n",
    "    model = keras.models.Model(\n",
    "        inputs=input_data, outputs=output, name=\"ocr_model\"\n",
    "    )\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=ctc_loss)\n",
    "    return model\n",
    "# Compile the model with CTC loss\n",
    "def ctc_loss(y_true, y_pred):\n",
    "    input_length = tf.fill((batch_size, 1), tf.shape(y_pred)[1])\n",
    "    label_length = tf.fill((batch_size, 1), max_length)\n",
    "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    return loss\n",
    "\n",
    "model=build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b954222",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='loss',\n",
    "        patience=5,\n",
    "        verbose=1,\n",
    "        restore_best_weights=True),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5445f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_epoch = history.history['val_loss'].index(min(history.history['val_loss']))\n",
    "def plot_training_history(history, best_epoch):\n",
    "    # Set a high-DPI figure (for sharper image)\n",
    "    plt.figure(figsize=(12, 8), dpi=150)  # Increase size and resolution\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    plt.title('Model Loss over Epochs', fontsize=16)\n",
    "    plt.xlabel('Epoch', fontsize=14)\n",
    "    plt.ylabel('Loss', fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Display the lowest validation loss and the epoch at which it occurred\n",
    "    min_val_loss = min(history.history['val_loss'])\n",
    "    plt.annotate(\n",
    "        f'Lowest Validation Loss: {min_val_loss:.4f}\\nEpoch: {best_epoch + 1}',\n",
    "        xy=(best_epoch, min_val_loss),\n",
    "        xytext=(best_epoch - 5, min_val_loss + 0.3),\n",
    "        arrowprops=dict(facecolor='black', arrowstyle='->'),\n",
    "        fontsize=12,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor='black', facecolor='white')\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_training_history(history, best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e86583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_and_visualize_samples(model, dataset, int_to_char, num_samples=5):\n",
    "\n",
    "    # Create an iterator for the dataset\n",
    "    dataset_iter = iter(dataset)\n",
    "\n",
    "    # Create a subplot grid\n",
    "    fig, axes = plt.subplots(num_samples, 1, figsize=(4, 2 * num_samples))\n",
    "\n",
    "    # Iterate through the random samples, decode, and visualize them\n",
    "    for i in range(num_samples):\n",
    "        image, label = next(dataset_iter)\n",
    "\n",
    "        # Make predictions using the model\n",
    "        predictions = model.predict(image)\n",
    "        # Decode the predictions using CTC decode\n",
    "        decoded, _ = keras.backend.ctc_decode(predictions, input_length=tf.fill((batch_size,), 25), greedy=True)\n",
    "\n",
    "        # Convert decoded labels to characters\n",
    "        decoded_labels = [int_to_char[int(x)] for x in decoded[0][0,:max_length].numpy()]\n",
    "\n",
    "        # Display the image and decoded label\n",
    "        axes[i].imshow(image[0, :, :, 0], cmap='gray')\n",
    "        axes[i].set_title(\"Decoded: \" + ''.join(decoded_labels))\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    # Adjust spacing and display the grid\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "decode_and_visualize_samples(model, validation_dataset, int_to_char, num_samples=5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
